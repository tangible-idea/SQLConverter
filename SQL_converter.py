import streamlit as st
import json
import pandas as pd
import os  # íŒŒì¼ ì´ë¦„ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€

# JSONL íŒŒì¼ ì½ê¸°
def read_jsonl(file):
    return [json.loads(line) for line in file]

# ë°ì´í„° íƒ€ì… ì¶”ë¡ 
def infer_column_types(data):
    all_keys = set()
    for entry in data:
        all_keys.update(entry.keys())

    column_types = {}
    for key in sorted(all_keys):
        sample_value = next((entry[key] for entry in data if key in entry), None)
        
        if isinstance(sample_value, bool):
            col_type = "BOOLEAN"
        elif isinstance(sample_value, int):
            col_type = "INTEGER"
        elif isinstance(sample_value, float):
            col_type = "FLOAT"
        elif isinstance(sample_value, list):
            col_type = "TEXT[]"  # PostgreSQL ë°°ì—´ íƒ€ì…
        else:
            col_type = "TEXT"
        
        column_types[key] = col_type

    return column_types

# CREATE TABLE SQL ìƒì„±
def generate_sql_create(table_name, column_types, primary_keys):
    columns_sql = ",\n    ".join(f'"{col}" {dtype}' for col, dtype in column_types.items())

    pk_sql = ""
    if primary_keys:
        pk_columns = ", ".join(f'"{col}"' for col in primary_keys)
        pk_sql = f",\n    PRIMARY KEY ({pk_columns})"

    return f"CREATE TABLE {table_name} (\n    {columns_sql}{pk_sql}\n);"

# INSERT INTO SQL ìƒì„±
def format_value(value, dtype):
    if isinstance(value, bool):
        return "TRUE" if value else "FALSE"
    elif isinstance(value, str):
        return "'{}'".format(value.replace("'", "''"))
    elif isinstance(value, list):
        if value:  # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°
            formatted_list = ",".join("'{}'".format(str(item).replace("'", "''")) for item in value)
            return f"ARRAY[{formatted_list}]"
        else:  # ë¹ˆ ë°°ì—´ì¼ ê²½ìš°
            return f"ARRAY[]::{dtype}"  # ë¹ˆ ë°°ì—´ì— ë°ì´í„° íƒ€ì… ëª…ì‹œ
    elif value is None:
        return "NULL"
    else:
        return str(value)

def generate_sql_insert(table_name, data, column_types):
    columns = ", ".join(f'"{col}"' for col in column_types.keys())
    values_list = []

    for entry in data:
        values = [format_value(entry.get(col, None), column_types[col]) for col in column_types.keys()]
        values_list.append(f"({', '.join(values)})")

    values_sql = ",\n    ".join(values_list)
    return f"INSERT INTO {table_name} ({columns}) VALUES\n    {values_sql};"

# Streamlit UI
st.title("JSONL â†’ PostgreSQL SQL ë³€í™˜ê¸°")

uploaded_file = st.file_uploader("JSONL íŒŒì¼ ì—…ë¡œë“œ", type=["jsonl"])

if uploaded_file:
    try:
        json_data = read_jsonl(uploaded_file)

        if not json_data:
            st.error("âŒ ì˜¬ë°”ë¥¸ JSONL ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            st.stop()

        # âœ… íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ê¸°ë³¸ í…Œì´ë¸” ì´ë¦„ ì„¤ì •
        default_table_name = os.path.splitext(uploaded_file.name)[0]

        # âœ… ì‚¬ìš©ìê°€ ì§ì ‘ í…Œì´ë¸” ì´ë¦„ ì…ë ¥ ê°€ëŠ¥ (ê¸°ë³¸ê°’: íŒŒì¼ ì´ë¦„)
        table_name = st.text_input("ğŸ“Œ í…Œì´ë¸” ì´ë¦„ ì…ë ¥", value=default_table_name)

        column_types = infer_column_types(json_data)

        # âœ… í…Œì´ë¸” í˜•íƒœë¡œ í•„ë“œ ì„ íƒ ë° ë°ì´í„° íƒ€ì… ë³€ê²½ ê°€ëŠ¥
        st.subheader("ğŸ“Œ ë³€í™˜í•  í•„ë“œ ì„ íƒ, ë°ì´í„° íƒ€ì… ìˆ˜ì •, PK ì§€ì •")

        # ë°ì´í„° í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame({
            "ì‚¬ìš©": [True] * len(column_types),  # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  í•„ë“œ ì„ íƒë¨
            "PK": [False] * len(column_types),   # ê¸°ë³¸ì ìœ¼ë¡œ PKëŠ” ì—†ìŒ
            "í•„ë“œëª…": list(column_types.keys()),
            "ë°ì´í„° íƒ€ì…": list(column_types.values())
        })

        # Streamlit ë°ì´í„° í¸ì§‘ ê¸°ëŠ¥ ì œê³µ
        edited_df = st.data_editor(
            df,
            column_config={
                "ì‚¬ìš©": st.column_config.CheckboxColumn("ì‚¬ìš©"),
                "PK": st.column_config.CheckboxColumn("PK"),
                "ë°ì´í„° íƒ€ì…": st.column_config.SelectboxColumn(
                    "ë°ì´í„° íƒ€ì…", options=["TEXT", "INTEGER", "FLOAT", "BOOLEAN", "TEXT[]"]
                )
            },
            disabled=["í•„ë“œëª…"],  # í•„ë“œëª…ì€ ìˆ˜ì • ë¶ˆê°€ëŠ¥
            use_container_width=True
        )

        # ì„ íƒëœ í•„ë“œë§Œ ë°˜ì˜
        selected_columns = edited_df[edited_df["ì‚¬ìš©"]]
        filtered_columns = dict(zip(selected_columns["í•„ë“œëª…"], selected_columns["ë°ì´í„° íƒ€ì…"]))
        primary_keys = list(edited_df[edited_df["PK"]]["í•„ë“œëª…"])

        # Run ë²„íŠ¼ í‘œì‹œ
        if st.button("ğŸš€ Run (CREATE & INSERT SQL ìƒì„±)"):
            if not filtered_columns:
                st.error("âŒ ìµœì†Œí•œ í•˜ë‚˜ ì´ìƒì˜ í•„ë“œë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
                st.stop()

            create_sql = generate_sql_create(table_name, filtered_columns, primary_keys)
            insert_sql = generate_sql_insert(table_name, json_data, filtered_columns)

            st.subheader("ğŸ“Œ ìƒì„±ëœ CREATE TABLE ì¿¼ë¦¬")
            st.code(create_sql, language="sql")

            st.subheader("ğŸ“Œ ìƒì„±ëœ INSERT INTO ì¿¼ë¦¬")
            st.code(insert_sql, language="sql")

            # SQL ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            sql_output = f"{create_sql}\n\n{insert_sql}"
            st.download_button("ğŸ“¥ SQL íŒŒì¼ ë‹¤ìš´ë¡œë“œ", sql_output, file_name="converted.sql", mime="text/sql")

    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")